{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 1: Means, Variances, and $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example solution provided by Tania Kozynets (AMAS-2021 TA), Feb. 8, 2021;\n",
    "\n",
    "see alternative solutions by [Jason](https://www.nbi.dk/~koskinen/Teaching/AdvancedMethodsInAppliedStatistics2020/Exercises/Lecture1_Variance.py) (course lecturer) and [Jean-Loup](https://www.nbi.dk/~koskinen/Teaching/AdvancedMethodsInAppliedStatistics2020/Exercises/Lecture1_Variance_Py3.ipynb) (AMAS-2019 TA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first read in the data as a [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), clean it up, and find the headers for each of the five datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data:\n",
    "data = pd.read_table('FranksNumbers.txt.1',header=1,sep='\\s+',\n",
    "                    names = ['x','y_measured','to_be_dropped'])\n",
    "\n",
    "#The last column now contains NaN values, which is why we drop it:\n",
    "data = data.drop(['to_be_dropped'],axis=1)\n",
    "\n",
    "#Next, we will check if the first symbol, data['x'][i][0], in each data row [i] is a digit.\n",
    "check_if_numerical = np.array([data['x'][i][0].isdigit() for i in range(len(data))])\n",
    "\n",
    "#If the above test was failed and the first symbol is not a digit, it must be a letter (in this case).\n",
    "#This means that we found a header for the next dataset. Recording the indices of all header rows in this manner:\n",
    "header_rows = np.where(check_if_numerical == False)[0]\n",
    "\n",
    "#We will also append -1 from above, since this is technically where the 1st header belongs.\n",
    "breaking_rows = np.append(-1,header_rows)\n",
    "breaking_rows = np.append(breaking_rows,len(data))\n",
    "\n",
    "#We will store the individual datasets in the dictionary below, starting with the row of the previous header\n",
    "#and ending with the row of the next header.\n",
    "individual_datasets = {}\n",
    "\n",
    "for dataset_number in range(len(header_rows)+1):\n",
    "    #We will also remember to change the format to float (as it used to be string before)\n",
    "    individual_datasets[dataset_number+1] = \\\n",
    "    data[breaking_rows[dataset_number]+1:breaking_rows[dataset_number+1]].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the mean and the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a function for calculating the variance of the given samples, using either biased (assuming _N_ DOF) or an unbiased (assuming _N-1_ DOF) estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_variance(samples,bias=False):\n",
    "    N = len(samples)\n",
    "    if bias:\n",
    "        return np.sum((samples-np.average(samples))**2)/N\n",
    "    else:\n",
    "        return np.sum((samples-np.average(samples))**2)/(N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will store the means and the variances as dictionaries as well, with dataset number being our key.\n",
    "means = {}\n",
    "unbiased_variances = {}\n",
    "biased_variances = {}\n",
    "\n",
    "for dataset_number in range(len(header_rows)+1):\n",
    "    #Create placeholders to compute variances for a given column of the dataset:\n",
    "    means[dataset_number+1] = {}\n",
    "    unbiased_variances[dataset_number+1] = {}\n",
    "    biased_variances[dataset_number+1] = {}\n",
    "    \n",
    "    #Loop through the columns. For us, these are \"x\" and \"y_measured\". \n",
    "    #We will only need to report the variance for the y variable in the end.\n",
    "    \n",
    "    for column in data.columns:\n",
    "        \n",
    "        #The mean calculation is done using the standard numpy.average function:\n",
    "        means[dataset_number+1][column] = np.average(individual_datasets[dataset_number+1][column])\n",
    "        \n",
    "        #The variance calculation is done using our custom calc_variance function, with the appropriate bias flag.\n",
    "        #For bias = False, one could alternatively use np.var(samples,ddof=1) as in Jason's solution.\n",
    "        unbiased_variances[dataset_number+1][column] = \\\n",
    "        calc_variance(individual_datasets[dataset_number+1][column], bias = False)\n",
    "        \n",
    "        #For bias = True, one could alternatively use np.var(samples,ddof=0) as in Jason's solution.\n",
    "        biased_variances[dataset_number+1][column] = \\\n",
    "        calc_variance(individual_datasets[dataset_number+1][column], bias = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the $\\chi^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a function to calculate the $\\chi^2$ given the expected data (y_expected), the observed data (y_measured) and the uncertainty on the observed data (y_err).\n",
    "\n",
    "This can work with any form of y_err, which is why we can reuse it for either Pearson's $\\chi^2$ with y_err = sqrt(y_expected) or y_err = 1.22 for all data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(y_expected,y_measured,y_err):\n",
    "    return np.sum((y_expected-y_measured)**2/(y_err**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The calculated chi2 values will be again stored as dictionaries with dataset numbers as keys.\n",
    "chi2_with_sqrt_unc = {}\n",
    "chi2_with_fixed_unc = {}\n",
    "\n",
    "reduced_chi2_with_sqrt_unc = {}\n",
    "reduced_chi2_with_fixed_unc = {}\n",
    "\n",
    "#Looping through the dataset numbers:\n",
    "for dataset_number in range(5):\n",
    "    \n",
    "    #The expected y value is calculated from the line equation provided in the lecture notes,\n",
    "    #i.e. 0.48*x + 3.02. \n",
    "    y_expected = individual_datasets[dataset_number+1]['x']*0.48 + 3.02\n",
    "    \n",
    "    #Now, we evaluate the chi2 using the function we have defined above.\n",
    "    #chi2_with_sqrt is the Pearson's chi2 with y_err = sqrt(y_measured).\n",
    "    #Note that it's not necessary to pass the keywords (y_expected=..., etc) to the function; this is done\n",
    "    #for purely illustrative purposes.\n",
    "    chi2_with_sqrt_unc[dataset_number+1] = chi2(y_expected = y_expected,\n",
    "                                           y_measured = individual_datasets[dataset_number+1]['y_measured'],\n",
    "                                           y_err = np.sqrt(y_expected))\n",
    "    \n",
    "    #chi2_with_fixed_unc is the chi2 assuming y_err = const = 1.22\n",
    "    chi2_with_fixed_unc[dataset_number+1] = chi2(y_expected = y_expected,\n",
    "                                           y_measured = individual_datasets[dataset_number+1]['y_measured'],\n",
    "                                           y_err = np.full_like(individual_datasets[dataset_number+1]['x'],1.22))\n",
    "    \n",
    "    #We can also calculate the reduced chi2 by dividing total chi2 by the number of DOF.\n",
    "    #Since we are trying to \"fit\" a line with 2 parameters (slope and interpect), we will be dividing \n",
    "    #by the number of DOF equal to N-2 here.\n",
    "    reduced_chi2_with_sqrt_unc[dataset_number+1] = chi2_with_sqrt_unc[dataset_number+1]/(len(y_expected)-2)\n",
    "    reduced_chi2_with_fixed_unc[dataset_number+1] = chi2_with_fixed_unc[dataset_number+1]/(len(y_expected)-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "Biased variance:    3.752\n",
      "Unbiased variance:    4.127\n",
      "Pearson's chi-squared (w/ sqrt uncertainty):    1.887\n",
      "Chi-squared (w/ ±1.22 uncertainty):    9.468\n",
      "Reduced Pearson's chi-squared (w/ sqrt uncertainty):    0.210\n",
      "Reduced chi-squared (w/ ±1.22 uncertainty):    1.052\n",
      "\n",
      "\n",
      "Dataset 2\n",
      "Biased variance:    3.752\n",
      "Unbiased variance:    4.128\n",
      "Pearson's chi-squared (w/ sqrt uncertainty):    2.072\n",
      "Chi-squared (w/ ±1.22 uncertainty):    9.477\n",
      "Reduced Pearson's chi-squared (w/ sqrt uncertainty):    0.230\n",
      "Reduced chi-squared (w/ ±1.22 uncertainty):    1.053\n",
      "\n",
      "\n",
      "Dataset 3\n",
      "Biased variance:    3.748\n",
      "Unbiased variance:    4.123\n",
      "Pearson's chi-squared (w/ sqrt uncertainty):    1.555\n",
      "Chi-squared (w/ ±1.22 uncertainty):    9.460\n",
      "Reduced Pearson's chi-squared (w/ sqrt uncertainty):    0.173\n",
      "Reduced chi-squared (w/ ±1.22 uncertainty):    1.051\n",
      "\n",
      "\n",
      "Dataset 4\n",
      "Biased variance:    3.748\n",
      "Unbiased variance:    4.123\n",
      "Pearson's chi-squared (w/ sqrt uncertainty):    2.043\n",
      "Chi-squared (w/ ±1.22 uncertainty):    9.454\n",
      "Reduced Pearson's chi-squared (w/ sqrt uncertainty):    0.227\n",
      "Reduced chi-squared (w/ ±1.22 uncertainty):    1.050\n",
      "\n",
      "\n",
      "Dataset 5\n",
      "Biased variance:    3.750\n",
      "Unbiased variance:    3.837\n",
      "Pearson's chi-squared (w/ sqrt uncertainty):    7.556\n",
      "Chi-squared (w/ ±1.22 uncertainty):    37.858\n",
      "Reduced Pearson's chi-squared (w/ sqrt uncertainty):    0.180\n",
      "Reduced chi-squared (w/ ±1.22 uncertainty):    0.901\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_number in range(5):\n",
    "    \n",
    "    print(\"Dataset %s\"%str(dataset_number+1))\n",
    "    \n",
    "    print(\"Biased variance:    {:.3f}\".format(biased_variances[dataset_number+1]['y_measured']))\n",
    "    print(\"Unbiased variance:    {:.3f}\".format(unbiased_variances[dataset_number+1]['y_measured']))\n",
    "    \n",
    "    print(\"Pearson's chi-squared (w/ sqrt uncertainty):    {:.3f}\".format(chi2_with_sqrt_unc[dataset_number+1]))\n",
    "    print(\"Chi-squared (w/ ±1.22 uncertainty):    {:.3f}\".format(chi2_with_fixed_unc[dataset_number+1]))\n",
    "\n",
    "    print(\"Reduced Pearson's chi-squared (w/ sqrt uncertainty):    {:.3f}\".format(reduced_chi2_with_sqrt_unc[dataset_number+1]))\n",
    "    print(\"Reduced chi-squared (w/ ±1.22 uncertainty):    {:.3f}\".format(reduced_chi2_with_fixed_unc[dataset_number+1]))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "py383"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
